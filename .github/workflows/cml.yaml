name: Model CI (Train, Test, Report)

on:
  push:
    branches: [main, develop]
  pull_request:

permissions:
  contents: read
  pull-requests: write

jobs:
  ci:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Lint with flake8
        continue-on-error: true
        run: |
          pip install flake8
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics || true
      
      - name: Pre-train tests (data validation)
        run: |
          python -m pytest tests/test_pretrain.py -v --tb=short
      
      - name: Train model
        run: |
          python src/train.py data/prepared data/models
      
      - name: Post-train tests (Quality Gate)
        env:
          F1_THRESHOLD: "0.15"
          ROC_THRESHOLD: "0.75"
        run: |
          python -m pytest tests/test_posttrain.py -v --tb=short
      
      - name: Generate metrics report
        if: github.event_name == 'pull_request'
        run: |
          python << 'EOF'
import json

with open("data/models/metrics.json", "r") as f:
    metrics = json.load(f)

f1_pass = "‚úÖ" if metrics['test_f1'] >= 0.15 else "‚ùå"
roc_pass = "‚úÖ" if metrics['test_roc_auc'] >= 0.75 else "‚ùå"
overfit_pass = "‚úÖ" if (metrics['train_f1'] - metrics['test_f1']) <= 0.30 else "‚ùå"

report = f"""# üìä Model Training Report

## Metrics Summary
| Metric | Value |
|--------|-------|
| F1-Score | {metrics['test_f1']:.4f} |
| ROC-AUC | {metrics['test_roc_auc']:.4f} |
| Accuracy | {metrics['test_accuracy']:.4f} |
| Train F1 | {metrics['train_f1']:.4f} |
| Overfitting Gap | {metrics['train_f1'] - metrics['test_f1']:.4f} |

## Quality Gate Status
- {f1_pass} F1-Score >= 0.15: {metrics['test_f1']:.4f}
- {roc_pass} ROC-AUC >= 0.75: {metrics['test_roc_auc']:.4f}
- {overfit_pass} Overfitting Gap <= 0.30: {metrics['train_f1'] - metrics['test_f1']:.4f}

## CI/CD Pipeline Status
‚úÖ Data validation passed
‚úÖ Model training completed
‚úÖ Tests passed
‚úÖ Artifacts generated

---
Generated by GitHub Actions | [View MLflow Experiment](https://mlflow.org)
"""

with open("report.md", "w") as f:
    f.write(report)
EOF
      
      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('report.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });
      
      - name: Upload model artifact (main only)
        if: github.ref == 'refs/heads/main' && github.event_name == 'push' && success()
        uses: actions/upload-artifact@v4
        with:
          name: best-model
          path: models/best_optimized_model.pkl
          retention-days: 30
